# è§†é¢‘ç”Ÿæˆæµç¨‹æµ‹è¯•æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [æµ‹è¯•ç›®æ ‡](#æµ‹è¯•ç›®æ ‡)
2. [æµ‹è¯•ç¯å¢ƒå‡†å¤‡](#æµ‹è¯•ç¯å¢ƒå‡†å¤‡)
3. [æµ‹è¯•æµç¨‹](#æµ‹è¯•æµç¨‹)
4. [æµ‹è¯•ç”¨ä¾‹](#æµ‹è¯•ç”¨ä¾‹)
5. [é—®é¢˜æ’æŸ¥](#é—®é¢˜æ’æŸ¥)

---

## 1. æµ‹è¯•ç›®æ ‡

### 1.1 ä¸»è¦ç›®æ ‡
- âœ… éªŒè¯ LLM æ¨¡å‹èƒ½å¦æ­£å¸¸ç”Ÿæˆè„šæœ¬
- âœ… éªŒè¯è§†é¢‘æ¨¡å‹èƒ½å¦æ­£å¸¸ç”Ÿæˆè§†é¢‘å¸§
- âœ… éªŒè¯è§†é¢‘å¤„ç†å™¨èƒ½å¦æ­£å¸¸ç¼–ç è§†é¢‘
- âœ… éªŒè¯ç«¯åˆ°ç«¯æµç¨‹æ˜¯å¦å®Œæ•´
- âœ… æµ‹é‡æ€§èƒ½æŒ‡æ ‡ï¼ˆæ—¶é—´ã€æ˜¾å­˜ï¼‰

### 1.2 æµ‹è¯•èŒƒå›´
- å•å…ƒæµ‹è¯•ï¼šå„æ¨¡å—ç‹¬ç«‹åŠŸèƒ½
- é›†æˆæµ‹è¯•ï¼šæ¨¡å—é—´åä½œ
- ç«¯åˆ°ç«¯æµ‹è¯•ï¼šå®Œæ•´æµç¨‹
- æ€§èƒ½æµ‹è¯•ï¼šé€Ÿåº¦å’Œèµ„æºå ç”¨

---

## 2. æµ‹è¯•ç¯å¢ƒå‡†å¤‡

### 2.1 ç¡¬ä»¶è¦æ±‚æ£€æŸ¥
```bash
# æ£€æŸ¥ GPU
nvidia-smi

# æ£€æŸ¥ CUDA
nvcc --version

# æ£€æŸ¥æ˜¾å­˜
nvidia-smi --query-gpu=memory.total --format=csv
```

**æœ€ä½è¦æ±‚**:
- GPU: NVIDIA RTX 3090 æˆ–æ›´é«˜
- æ˜¾å­˜: 24GB
- å†…å­˜: 32GB RAM

### 2.2 è½¯ä»¶ç¯å¢ƒæ£€æŸ¥
```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python --version  # éœ€è¦ 3.10+

# æ£€æŸ¥ä¾èµ–
pip list | grep -E "torch|transformers|diffusers"
```

### 2.3 æ¨¡å‹æ–‡ä»¶æ£€æŸ¥
```bash
# æ£€æŸ¥ LLM æ¨¡å‹
ls -lh backend/models/chatglm3-6b/

# æ£€æŸ¥è§†é¢‘æ¨¡å‹
ls -lh backend/models/svd-xt/
```

---

## 3. æµ‹è¯•æµç¨‹

### 3.1 é˜¶æ®µ 1: ç¯å¢ƒéªŒè¯æµ‹è¯•

#### æµ‹è¯• 1.1: éªŒè¯è„šæœ¬
```bash
cd backend
python ../scripts/verify_setup.py
```

**é¢„æœŸè¾“å‡º**:
```
âœ… Python ç‰ˆæœ¬
âœ… CUDA
âœ… ä¾èµ–åŒ…
âœ… ç›®å½•ç»“æ„
âš ï¸ æ¨¡å‹æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
```

#### æµ‹è¯• 1.2: å¯¼å…¥æµ‹è¯•
```python
# test_imports.py
import torch
from transformers import AutoModel, AutoTokenizer
from diffusers import StableVideoDiffusionPipeline
from PIL import Image
import cv2

print("âœ… æ‰€æœ‰ä¾èµ–å¯¼å…¥æˆåŠŸ")
```

---

### 3.2 é˜¶æ®µ 2: å•å…ƒæµ‹è¯•

#### æµ‹è¯• 2.1: LLM æœåŠ¡æµ‹è¯•
```bash
pytest tests/test_llm_service.py -v
```

**æµ‹è¯•å†…å®¹**:
- å¤‡ç”¨è„šæœ¬ç”Ÿæˆ
- JSON è§£æ
- è„šæœ¬éªŒè¯

#### æµ‹è¯• 2.2: è§†é¢‘å¤„ç†å™¨æµ‹è¯•
```bash
pytest tests/test_video_service.py -v
```

**æµ‹è¯•å†…å®¹**:
- å ä½ç¬¦å›¾åƒç”Ÿæˆ
- å¸§è½¬è§†é¢‘
- å¸§æ’å€¼

---

### 3.3 é˜¶æ®µ 3: æ¨¡å‹åŠ è½½æµ‹è¯•

#### æµ‹è¯• 3.1: LLM æ¨¡å‹åŠ è½½
```python
# test_llm_loading.py
from services.model_loader import llm_loader
import time

start = time.time()
success = llm_loader.load_model()
duration = time.time() - start

print(f"LLM åŠ è½½: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
print(f"è€—æ—¶: {duration:.2f} ç§’")

if success:
    # æµ‹è¯•ç”Ÿæˆ
    response = llm_loader.generate("ä½ å¥½")
    print(f"ç”Ÿæˆæµ‹è¯•: {response[:50]}")
```

**é¢„æœŸç»“æœ**:
- åŠ è½½æ—¶é—´: 30-60 ç§’
- æ˜¾å­˜å ç”¨: 10-12GB
- ç”ŸæˆæˆåŠŸ

#### æµ‹è¯• 3.2: è§†é¢‘æ¨¡å‹åŠ è½½
```python
# test_video_loading.py
from services.model_loader import video_loader
import time

start = time.time()
success = video_loader.load_model()
duration = time.time() - start

print(f"è§†é¢‘æ¨¡å‹åŠ è½½: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
print(f"è€—æ—¶: {duration:.2f} ç§’")
```

**é¢„æœŸç»“æœ**:
- åŠ è½½æ—¶é—´: 60-120 ç§’
- æ˜¾å­˜å ç”¨: 8-10GB
- åŠ è½½æˆåŠŸ

---

### 3.4 é˜¶æ®µ 4: åŠŸèƒ½æµ‹è¯•

#### æµ‹è¯• 4.1: è„šæœ¬ç”Ÿæˆæµ‹è¯•
```python
# test_script_generation.py
from services.llm_service import generate_script

prompts = [
    "åˆ¶ä½œä¸€æ®µå…³äºæ£®æ—æ¢é™©çš„çŸ­è§†é¢‘",
    "åˆ¶ä½œä¸€æ®µå…³äºæµ·æ»©æ—¥è½çš„è§†é¢‘",
    "åˆ¶ä½œä¸€æ®µå…³äºåŸå¸‚å¤œæ™¯çš„è§†é¢‘"
]

for prompt in prompts:
    print(f"\næµ‹è¯•æç¤ºè¯: {prompt}")
    script = generate_script(prompt)
    
    print(f"åœºæ™¯æ•°: {len(script['scenes'])}")
    print(f"æ€»æ—¶é•¿: {script['total_duration']} ç§’")
    
    for scene in script['scenes'][:2]:
        print(f"  åœºæ™¯ {scene['scene_number']}: {scene['description'][:40]}")
```

**é¢„æœŸç»“æœ**:
- ç”Ÿæˆæ—¶é—´: 5-10 ç§’
- åœºæ™¯æ•°: 3-8 ä¸ª
- æè¿°è¯¦ç»†

#### æµ‹è¯• 4.2: å•åœºæ™¯è§†é¢‘ç”Ÿæˆæµ‹è¯•
```python
# test_single_scene.py
from services.video_service_new import generate_scene_video
import time

scene = {
    "scene_number": 1,
    "description": "é˜³å…‰æ˜åªšçš„æ£®æ—ï¼Œé¸Ÿå„¿åœ¨æ ‘æä¸Šæ­Œå”±",
    "duration": 3
}

print("å¼€å§‹ç”Ÿæˆå•åœºæ™¯è§†é¢‘...")
start = time.time()

try:
    video_path = generate_scene_video(scene, "test_single")
    duration = time.time() - start
    
    print(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ")
    print(f"è·¯å¾„: {video_path}")
    print(f"è€—æ—¶: {duration:.2f} ç§’")
    
    # æ£€æŸ¥æ–‡ä»¶
    import os
    if os.path.exists(video_path):
        size = os.path.getsize(video_path) / 1024 / 1024
        print(f"æ–‡ä»¶å¤§å°: {size:.2f} MB")
    
except Exception as e:
    print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
```

**é¢„æœŸç»“æœ**:
- ç”Ÿæˆæ—¶é—´: 2-5 åˆ†é’Ÿ
- æ–‡ä»¶å¤§å°: 1-5 MB
- è§†é¢‘å¯æ’­æ”¾

---

### 3.5 é˜¶æ®µ 5: ç«¯åˆ°ç«¯æµ‹è¯•

#### æµ‹è¯• 5.1: å®Œæ•´æµç¨‹æµ‹è¯•
```python
# test_end_to_end.py
from services.llm_service import generate_script
from services.video_service_new import generate_video_from_script
import time

print("=" * 60)
print("ç«¯åˆ°ç«¯è§†é¢‘ç”Ÿæˆæµ‹è¯•")
print("=" * 60)

# æ­¥éª¤ 1: ç”Ÿæˆè„šæœ¬
prompt = "åˆ¶ä½œä¸€æ®µå…³äºæ£®æ—æ¢é™©çš„çŸ­è§†é¢‘ï¼ŒåŒ…å«æ²³æµå’Œå°åŠ¨ç‰©"
print(f"\næ­¥éª¤ 1: ç”Ÿæˆè„šæœ¬")
print(f"æç¤ºè¯: {prompt}")

start_script = time.time()
script = generate_script(prompt)
script_time = time.time() - start_script

print(f"âœ… è„šæœ¬ç”Ÿæˆå®Œæˆ")
print(f"åœºæ™¯æ•°: {len(script['scenes'])}")
print(f"è€—æ—¶: {script_time:.2f} ç§’")

# æ­¥éª¤ 2: ç”Ÿæˆè§†é¢‘
print(f"\næ­¥éª¤ 2: ç”Ÿæˆè§†é¢‘")
start_video = time.time()

try:
    video_path = generate_video_from_script(script, "test_e2e")
    video_time = time.time() - start_video
    
    print(f"âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ")
    print(f"è·¯å¾„: {video_path}")
    print(f"è€—æ—¶: {video_time:.2f} ç§’")
    
    # æ€»ç»“
    total_time = script_time + video_time
    print(f"\n" + "=" * 60)
    print(f"æ€»è€—æ—¶: {total_time:.2f} ç§’ ({total_time/60:.2f} åˆ†é’Ÿ)")
    print(f"  - è„šæœ¬ç”Ÿæˆ: {script_time:.2f} ç§’")
    print(f"  - è§†é¢‘ç”Ÿæˆ: {video_time:.2f} ç§’")
    print("=" * 60)
    
except Exception as e:
    print(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
    import traceback
    traceback.print_exc()
```

**é¢„æœŸç»“æœ**:
- è„šæœ¬ç”Ÿæˆ: 5-10 ç§’
- è§†é¢‘ç”Ÿæˆ: 10-20 åˆ†é’Ÿ
- æ€»æ—¶é•¿: 10-20 åˆ†é’Ÿ
- è§†é¢‘å¯æ’­æ”¾

---

### 3.6 é˜¶æ®µ 6: æ€§èƒ½æµ‹è¯•

#### æµ‹è¯• 6.1: æ˜¾å­˜ç›‘æ§
```python
# test_memory_usage.py
import torch
from services.model_loader import llm_loader, video_loader

def print_memory():
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"æ˜¾å­˜: å·²åˆ†é… {allocated:.2f} GB, å·²ä¿ç•™ {reserved:.2f} GB")

print("åˆå§‹çŠ¶æ€:")
print_memory()

print("\nåŠ è½½ LLM æ¨¡å‹...")
llm_loader.load_model()
print_memory()

print("\nåŠ è½½è§†é¢‘æ¨¡å‹...")
video_loader.load_model()
print_memory()

print("\nç”Ÿæˆæµ‹è¯•...")
# æ‰§è¡Œç”Ÿæˆ
print_memory()

print("\nå¸è½½æ¨¡å‹...")
llm_loader.unload_model()
video_loader.unload_model()
torch.cuda.empty_cache()
print_memory()
```

#### æµ‹è¯• 6.2: é€Ÿåº¦åŸºå‡†æµ‹è¯•
```python
# test_benchmark.py
import time
from services.llm_service import generate_script
from services.video_service_new import generate_scene_video

# æµ‹è¯•è„šæœ¬ç”Ÿæˆé€Ÿåº¦
prompts = [
    "æ£®æ—æ¢é™©",
    "æµ·æ»©æ—¥è½",
    "åŸå¸‚å¤œæ™¯"
]

script_times = []
for prompt in prompts:
    start = time.time()
    generate_script(prompt)
    duration = time.time() - start
    script_times.append(duration)

print(f"è„šæœ¬ç”Ÿæˆå¹³å‡æ—¶é—´: {sum(script_times)/len(script_times):.2f} ç§’")

# æµ‹è¯•è§†é¢‘ç”Ÿæˆé€Ÿåº¦
scene = {
    "scene_number": 1,
    "description": "æµ‹è¯•åœºæ™¯",
    "duration": 2
}

start = time.time()
generate_scene_video(scene, "benchmark")
video_time = time.time() - start

print(f"å•åœºæ™¯è§†é¢‘ç”Ÿæˆæ—¶é—´: {video_time:.2f} ç§’")
```

---

## 4. æµ‹è¯•ç”¨ä¾‹

### 4.1 åŸºç¡€æµ‹è¯•ç”¨ä¾‹

| æµ‹è¯•ID | æµ‹è¯•å†…å®¹ | è¾“å…¥ | é¢„æœŸè¾“å‡º | ä¼˜å…ˆçº§ |
|--------|----------|------|----------|--------|
| T001 | ç¯å¢ƒéªŒè¯ | - | æ‰€æœ‰æ£€æŸ¥é€šè¿‡ | P0 |
| T002 | LLMåŠ è½½ | - | åŠ è½½æˆåŠŸ | P0 |
| T003 | è§†é¢‘æ¨¡å‹åŠ è½½ | - | åŠ è½½æˆåŠŸ | P0 |
| T004 | è„šæœ¬ç”Ÿæˆ | ç®€å•æç¤ºè¯ | 3-8ä¸ªåœºæ™¯ | P0 |
| T005 | å•åœºæ™¯è§†é¢‘ | å•ä¸ªåœºæ™¯ | MP4æ–‡ä»¶ | P0 |
| T006 | å®Œæ•´æµç¨‹ | å®Œæ•´æç¤ºè¯ | å®Œæ•´è§†é¢‘ | P0 |

### 4.2 è¾¹ç•Œæµ‹è¯•ç”¨ä¾‹

| æµ‹è¯•ID | æµ‹è¯•å†…å®¹ | è¾“å…¥ | é¢„æœŸè¡Œä¸º |
|--------|----------|------|----------|
| T101 | ç©ºæç¤ºè¯ | "" | ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ |
| T102 | è¶…é•¿æç¤ºè¯ | 500å­— | æ­£å¸¸å¤„ç†æˆ–æˆªæ–­ |
| T103 | ç‰¹æ®Šå­—ç¬¦ | "!@#$%" | æ­£å¸¸å¤„ç† |
| T104 | å¤šè¯­è¨€ | è‹±æ–‡/ä¸­æ–‡ | æ­£å¸¸å¤„ç† |

### 4.3 å¼‚å¸¸æµ‹è¯•ç”¨ä¾‹

| æµ‹è¯•ID | æµ‹è¯•å†…å®¹ | åœºæ™¯ | é¢„æœŸè¡Œä¸º |
|--------|----------|------|----------|
| T201 | æ˜¾å­˜ä¸è¶³ | æ¨¡æ‹Ÿæ˜¾å­˜ä¸è¶³ | ä¼˜é›…é™çº§ |
| T202 | æ¨¡å‹æœªåŠ è½½ | ç›´æ¥è°ƒç”¨ç”Ÿæˆ | ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ |
| T203 | ç½‘ç»œä¸­æ–­ | ä¸‹è½½æ¨¡å‹æ—¶ | é”™è¯¯æç¤º |

---

## 5. é—®é¢˜æ’æŸ¥

### 5.1 å¸¸è§é—®é¢˜

#### é—®é¢˜ 1: LLM æ¨¡å‹åŠ è½½å¤±è´¥
**ç—‡çŠ¶**: 
```
âŒ LLM æ¨¡å‹åŠ è½½å¤±è´¥: No module named 'transformers'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
pip install transformers torch accelerate
```

#### é—®é¢˜ 2: è§†é¢‘æ¨¡å‹åŠ è½½å¤±è´¥
**ç—‡çŠ¶**:
```
âŒ è§†é¢‘æ¨¡å‹åŠ è½½å¤±è´¥: No module named 'diffusers'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
pip install diffusers xformers
```

#### é—®é¢˜ 3: æ˜¾å­˜ä¸è¶³
**ç—‡çŠ¶**:
```
CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆ**:
1. ä½¿ç”¨ FP16: `VIDEO_CONFIG["use_fp16"] = True`
2. å‡å°‘å¸§æ•°: `VIDEO_CONFIG["num_frames"] = 15`
3. é™ä½åˆ†è¾¨ç‡: `VIDEO_CONFIG["height"] = 512`

#### é—®é¢˜ 4: ç”Ÿæˆé€Ÿåº¦æ…¢
**ç—‡çŠ¶**: å•åœºæ™¯ç”Ÿæˆè¶…è¿‡ 10 åˆ†é’Ÿ

**è§£å†³æ–¹æ¡ˆ**:
1. å‡å°‘æ¨ç†æ­¥æ•°: `VIDEO_CONFIG["num_inference_steps"] = 15`
2. å®‰è£… xformers: `pip install xformers`
3. æ£€æŸ¥ GPU åˆ©ç”¨ç‡: `nvidia-smi`

#### é—®é¢˜ 5: è§†é¢‘æ— æ³•æ’­æ”¾
**ç—‡çŠ¶**: ç”Ÿæˆçš„ MP4 æ–‡ä»¶æ— æ³•æ’­æ”¾

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥æ–‡ä»¶å¤§å°: `ls -lh video.mp4`
2. ä½¿ç”¨ VLC æ’­æ”¾å™¨
3. æ£€æŸ¥ç¼–ç å™¨: ç¡®ä¿å®‰è£…äº† ffmpeg

---

## 6. æµ‹è¯•æŠ¥å‘Šæ¨¡æ¿

### 6.1 æµ‹è¯•æ‰§è¡Œè®°å½•

```markdown
# è§†é¢‘ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š

## æµ‹è¯•ä¿¡æ¯
- æµ‹è¯•æ—¥æœŸ: YYYY-MM-DD
- æµ‹è¯•äººå‘˜: XXX
- æµ‹è¯•ç¯å¢ƒ: GPUå‹å·, æ˜¾å­˜å¤§å°

## æµ‹è¯•ç»“æœ

### ç¯å¢ƒéªŒè¯
- [ ] Python ç‰ˆæœ¬æ£€æŸ¥
- [ ] CUDA æ£€æŸ¥
- [ ] ä¾èµ–åŒ…æ£€æŸ¥
- [ ] æ¨¡å‹æ–‡ä»¶æ£€æŸ¥

### å•å…ƒæµ‹è¯•
- [ ] LLM æœåŠ¡æµ‹è¯•
- [ ] è§†é¢‘å¤„ç†å™¨æµ‹è¯•
- [ ] æ¨¡å‹åŠ è½½æµ‹è¯•

### åŠŸèƒ½æµ‹è¯•
- [ ] è„šæœ¬ç”Ÿæˆæµ‹è¯•
- [ ] å•åœºæ™¯è§†é¢‘ç”Ÿæˆ
- [ ] å®Œæ•´æµç¨‹æµ‹è¯•

### æ€§èƒ½æµ‹è¯•
- LLM åŠ è½½æ—¶é—´: XX ç§’
- è§†é¢‘æ¨¡å‹åŠ è½½æ—¶é—´: XX ç§’
- è„šæœ¬ç”Ÿæˆæ—¶é—´: XX ç§’
- å•åœºæ™¯ç”Ÿæˆæ—¶é—´: XX åˆ†é’Ÿ
- å®Œæ•´è§†é¢‘ç”Ÿæˆæ—¶é—´: XX åˆ†é’Ÿ
- æ˜¾å­˜å ç”¨: XX GB

## é—®é¢˜è®°å½•
1. é—®é¢˜æè¿°
   - è§£å†³æ–¹æ¡ˆ
   - çŠ¶æ€: å·²è§£å†³/å¾…è§£å†³

## æ€»ç»“
- é€šè¿‡æµ‹è¯•: X/Y
- ä¸»è¦é—®é¢˜: XXX
- å»ºè®®: XXX
```

---

## 7. è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

### 7.1 å®Œæ•´æµ‹è¯•è„šæœ¬
```bash
#!/bin/bash
# run_all_tests.sh

echo "å¼€å§‹å®Œæ•´æµ‹è¯•æµç¨‹..."

# 1. ç¯å¢ƒéªŒè¯
echo "1. ç¯å¢ƒéªŒè¯..."
python scripts/verify_setup.py

# 2. å•å…ƒæµ‹è¯•
echo "2. å•å…ƒæµ‹è¯•..."
pytest tests/ -v

# 3. æ¨¡å‹åŠ è½½æµ‹è¯•
echo "3. æ¨¡å‹åŠ è½½æµ‹è¯•..."
python tests/test_model_loading.py

# 4. åŠŸèƒ½æµ‹è¯•
echo "4. åŠŸèƒ½æµ‹è¯•..."
python tests/test_script_generation.py
python tests/test_single_scene.py

# 5. ç«¯åˆ°ç«¯æµ‹è¯•
echo "5. ç«¯åˆ°ç«¯æµ‹è¯•..."
python tests/test_end_to_end.py

# 6. æ€§èƒ½æµ‹è¯•
echo "6. æ€§èƒ½æµ‹è¯•..."
python tests/test_benchmark.py

echo "æµ‹è¯•å®Œæˆï¼"
```

---

## 8. æŒç»­é›†æˆ

### 8.1 GitHub Actions é…ç½®
```yaml
name: Video Generation Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install -r backend/requirements.txt
    
    - name: Run tests
      run: |
        pytest tests/ -v
```

---

## 9. å‚è€ƒèµ„æº

- [PyTorch æ–‡æ¡£](https://pytorch.org/docs/)
- [Transformers æ–‡æ¡£](https://huggingface.co/docs/transformers)
- [Diffusers æ–‡æ¡£](https://huggingface.co/docs/diffusers)
- [OpenCV æ–‡æ¡£](https://docs.opencv.org/)
